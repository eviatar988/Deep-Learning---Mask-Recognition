{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ad9613e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import os # to interact with the file system\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import cv2  # to read the images and to do image processing \n",
    "import gc # to clear our memories\n",
    "from tqdm import tqdm # to show the progress bar dynamically\n",
    "from glob import glob # find the pattern of all the images\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dde4a6c7",
   "metadata": {},
   "source": [
    "# PRE-PROCCESS THE DATA"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "28b5f2fa",
   "metadata": {},
   "source": [
    "Collect the train images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e640a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#collect all the images and label them into 4 labels\n",
    "\n",
    "dirs = os.listdir('data')\n",
    "images_path =[]\n",
    "labels = []  \n",
    "\n",
    "for folder in dirs:\n",
    "    path = glob('./data/{}/*.jpg'.format(folder)) # extract all the images from the folder\n",
    "    label = ['{}'.format(folder)] * len(path) # create a list of labels\n",
    "    # append the path and label to the list\n",
    "    images_path.extend(path)\n",
    "    labels.extend(label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98f6e9f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# face detection\n",
    "# identify the face in the image and crop the image to the face only, using pre-trained model- DNN (Deep Neural Network) in OpenCV\n",
    "\n",
    "img_path=images_path[1]\n",
    "img=cv2.imread(img_path) # read the image using open cv2\n",
    "\n",
    "cv2.imshow('original image',img) # show the original image\n",
    "cv2.waitKey(0) # wait for the key to be pressed\n",
    "cv2.destroyAllWindows() # close the window\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "40e9cd0c",
   "metadata": {},
   "source": [
    "Load pre-trained Face detection model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7f3f914",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the pre-trained model (face detection model - Caffe model)\n",
    "face_detection_model = cv2.dnn.readNetFromCaffe('./models/deploy.prototxt.txt','./models/res10_300x300_ssd_iter_140000_fp16.caffemodel')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ec90ec10",
   "metadata": {},
   "source": [
    "Creat func that get image, detect the faces, and return the crop faces,\n",
    "using loaded face detection model - Caffe model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "889c4d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def face_detection_dnn(img):\n",
    "    #calculate the blob from image (rgb mean subtraction)\n",
    "    image=img.copy() # copy the image to avoid any changes to the original image\n",
    "    h,w=image.shape[:2] # obtain the height and width of the image\n",
    "    blob=cv2.dnn.blobFromImage(image,1,(300,300),(104.0,177.0,123.0),swapRB=True) # claculate the blob from image (rgb mean subtraction)\n",
    "\n",
    "    # pass the blob to the face detection model and obtain the detections and predictions\n",
    "    face_detection_model.setInput(blob) # pass the blob to the face detection model\n",
    "    detections=face_detection_model.forward() # obtain the detections and predictions\n",
    "\n",
    "\n",
    "    #print(detections.shape) # print the shape of the detections \n",
    "    #(the '200' means the number of bounding boxes detected), 7 is the number of bbox that contain the face ) \n",
    "\n",
    "    for i in range(0,detections.shape[2]): # loop through the detections\n",
    "        confidence=detections[0,0,i,2] # obtain the confidence score for each detection\n",
    "        if confidence>0.5: # filter out weak detections\n",
    "            box=detections[0,0,i,3:7]*np.array([w,h,w,h]) # calculate the bounding box of the face\n",
    "            box=box.astype('int') # convert the bounding box to integer\n",
    "            #print(box) # print the bounding box\n",
    "            pt1=(box[0],box[1]) # obtain the top left corner of the bounding box\n",
    "            pt2=(box[2],box[3]) # obtain the bottom right corner of the bounding box\n",
    "            #cv2.rectangle(image,pt1,pt2,(0,255,0),2) # draw the bounding box on the image\n",
    "            roi = image[box[1]:box[3],box[0]:box[2]] # crop the image to the face only\n",
    "            return roi\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf5e3b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_roi=face_detection_dnn(img) # obtain the cropped image\n",
    "cv2.imshow('cropped image',img_roi) # show the cropped image\n",
    "cv2.imshow('original image',img) # show the original image\n",
    "cv2.waitKey(0) # wait for the key to be pressed\n",
    "cv2.destroyAllWindows() # close the window"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6489e17c",
   "metadata": {},
   "source": [
    "Creat blob from image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fbd4cd56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def datapreprocess(img):\n",
    "#create blob from image (rgb mean subtraction)\n",
    "\n",
    "    face = face_detection_dnn(img) # obtain the cropped image\n",
    "    if face is not None: # if the face is detected\n",
    "\n",
    "        #computing blob from image \n",
    "        blob = cv2.dnn.blobFromImage(face,1,(100,100),(104,117,123),swapRB=True) # claculate the blob from image (rgb mean subtraction)\n",
    "        blob_squeezed = np.squeeze(blob).T # squeeze the blob , reduce the dimension of the array and transpose \n",
    "        #--> Because The standard way to represent image is (height,width,channel = 3 -RGB) the blob resolt before was 4D array \n",
    "        blob_rotate = cv2.rotate(blob_squeezed,cv2.ROTATE_90_CLOCKWISE) # rotate the blob 90 degree clockwise\n",
    "        blob_flip = cv2.flip(blob_rotate,1) # flip the blob horizontally\n",
    "\n",
    "        #remove negative values and normalize the blob\n",
    "        img_norm=np.maximum(blob_flip,0)/blob_flip.max() #any negative values will be set to 0 and normalize the blob\n",
    "\n",
    "        return img_norm # return the normalized blob\n",
    "    else:\n",
    "        return None\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6e64cdea",
   "metadata": {},
   "source": [
    "APPLY TO ALL IMAGE AND APPEND IN A LIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a325f235",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "preprocessing images: 10000it [09:12, 18.11it/s]\n"
     ]
    }
   ],
   "source": [
    "#apply the function to all the images\n",
    "\n",
    "data_img =[] # create an empty list to store the processed images\n",
    "label_img=[] # create an empty list to store the labels\n",
    "\n",
    "\n",
    "i=0 #garbage collector counter\n",
    "\n",
    "for path, label in tqdm(zip(images_path,labels),desc='preprocessing images'): # for loop through the image path\n",
    "    img=cv2.imread(path) # read the image using open cv2\n",
    "    proccess_img=datapreprocess(img) # apply the function to the image\n",
    "    if proccess_img is not None: # if the image is not None\n",
    "        data_img.append(proccess_img) # append the image to the list\n",
    "        label_img.append(label) # append the label to the list\n",
    "\n",
    "    \n",
    "    i+=1 # increase the garbage collector counter\n",
    "    if i%100 == 0: # if the garbage collector counter is equal to 100\n",
    "        gc.collect() # clear the memory      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7ad18267",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=np.array(data_img) # convert the list to numpy array\n",
    "y=np.array(label_img) # convert the list to numpy array\n",
    "\n",
    "#print(x.shape) # print the shape of the x\n",
    "#print(y.shape) # print the shape of the y\n",
    "np.savez('./data/data_preprocess_lite.npz',x,y) # save the data and label to the npz file"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
